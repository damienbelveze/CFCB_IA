---
title: "Définitions"
---

# Larges Modèles de Langage (LLM)

Un LLM permet de réaliser une série de calculs sur la langue. Je peux par exemple savoir où se trouve un mot ou une phrase dans un espace linguistique particulier, calculer sa distance par rapport à d’autres mots ou d’autres phrases et donc chercher des synonymes, des contraires, etc. Je peux chercher un mot ou une phrase qui a une position semblable dans une autre langue et donc essayer de trouver une traduction, etc. Je peux par exemple prendre une série de mots et chercher les mots les plus probables qui suivent ces mots (@.

# chatbot 

Souvent utilisé pour désigner l'ensemble de l'application (le chatbot et le LLM), le chatbot, au sens strict, ne désigne que l'interpréteur de prompt qui va interroger le LLM. Ainsi dans le cas de ChatGPT, le LLM est GPT et le chatbot chatGPT. Le chatbot prend l'apparence d'une interface graphique. 


# entraînement

Un modèle est dit pré-entraîné c'est à dire qu'il se base sur des grandes masses de données pour devenir plus statistiquement pertinent. 
Une phase postérieure d'apprentissage renforcé complète cet entraînement. L'apprentissage renforcé consiste à faire des requêtes et à évaluer les résultats afin d'orienter le modèle vers de meilleures réponses (meilleures selon le but poursuivi par les concepteurs). L'apprentissage renforcé permet d'atténuer certains biais présents dans le corpus ou supprimer toutes les réponses jugées inappropriées (il est arrivé par le passé qu'en entrant ses symptomes sur un chatbot, un usager ait reçu comme réponse que la meilleure option thérapeutique pour lui consistait à se suicider ; on veut évidemment se prémunier au maximum contre cette éventualité). Les personnes sollicitées pour les périodes de renforcement sont la plupart du temps des personnes très mal rémunérées et dont l'exposition à des contenus problématiques est très peu prise en compte par les firmes qui développent les modèles. 

# jetons (tokens)

Le token (et non la page ou la ligne) est l'unité de base pour mesurer les quantités de données qui ont servi à entraîner un LLM ou les quantités de données qui sont générées par un chatbot (cette quantité est d'ailleurs souvent paramétrable). 
Statistiquement, le token constitue entre les 2/3 et les 3/4 d'un mot. 
Le procédé qui consiste à convertir une ligne de texte ou de code en tokens s'appelle la tokenisation. 

Un LLM comme codeqwen est entraîné avec des trillions (milliers de milliards) de tokens. 
La phrase suivante : "longtemps je me suis couché de bonne heure" comporte 8 mots, 42 caractères mais -pour [le LLM GPT4](https://platform.openai.com/tokenizer)- 10 tokens : 

|1|2|3|4|5|6|7|8|9|10|
|long|temps| je| me| suis| cou|ché| de|bonne|heure|

Le propre d'un LLM est de calculer les probabilités qu'un token se retrouve proche d'un autre token (par exemple que "cou" soit suivi de "ché" et non pas de "per" ou de "rrier")


## Activité : 

Aller sur Vittascience

Lancer un prompt (garder Mixtral, le LLM par défaut sur Vittascience). 
Compter le nombre de tokens obtenu.
Relancer la génération à partir d'un token qui se termine en milieu de mot et relancer la génération du prompt à partir d'une proposition statistiquement moins élevée. 


# température

Part d'aléatoire plus ou moins grande et souvent paramétrable pour l'usager dans la succession des tokens. Plus l'aléatoire (température) est faible et plus la suite de caractères est déterministe et s'éloigne très peu des cas majoritaires dans les données d'entraînement. (Dans Vittascience, les jetons les plus déterministes sont en vert foncé). Plus cet aléatoire est grand et plus le résultat sera éloigné de ce déterminisme. On aura des textes plus "créatifs" souvent illisibles quand la température est poussée à son maximum. 

## Activité : 

Dans Vittascience, faire un haïku sur un sujet de votre choix (par exemple la pluie en Bretagne) avec une température faible (20%) et envoyez la même instruction avec une température élevée (75%) ; comparez les résultats. Lequel préférez-vous ? 

![haikus réalisés par Mixtral](images/haikus.png)

Question : si je souhaite publier ces haïkus, est-ce que je peux le faire et toucher des droits d'auteur sur ma publication ? 
Qui est auteur dans ce cas : 
- moi en tant qu'auteur du prompt ? 
- vittascience en tant que concepteur du site ? 
- Mistral en tant que concepteur du LLM Mixtral avec lequel j'ai généré le prompt ? 









